abstracta daily systemic risk measure is proposed accounting for links and mutualdependencies between financial institutions utilising tail event information frmfinancial risk meter is based on lasso quantile regression designed to capturetail event comovements the frm focus lies on understanding active set datacharacteristics and the presentation of interdependencies in a network topologytwo frm indices are presented namely frmamericas and frmeurope the frmindices detect systemic risk at selected areas and identifies risk factors inpractice frm is applied to the return time series of selected financialinstitutions and macroeconomic risk factors using frm on a daily basis weidentify companies exhibiting extreme costress as well as activators ofstress with the srmeuroarea we extend to the government bond asset class frmis a good predictor for recession probabilities constituting the frmimpliedrecession probabilities thereby frm indicates tail event behaviour in anetwork of financial risk factorskeywordssystemic risk quantile regression financial markets risk management networkdynamics recession sep abstractthis research analyses highfrequency data of the cryptocurrency market inregards to intraday trading patterns we study trading quantitatives such asreturns traded volumes volatility periodicity and provide summary statisticsof return correlations to crix cryptocurrency index as well as respectiveoverall highfrequency based market statistics our results provide mandatoryinsight into a market where the grand scale employment of automated tradingalgorithms and the extremely rapid execution of trades might seem to be astandard based on media reports our findings on intraday momentum of tradingpatterns lead to a new view on approaching the predictability of economic valuein this new digital marketkeywordscryptocurrency highfrequency trading algorithmic trading liquidityvolatility price impact crix sep abstractwe propose an approach to calibrate the conditional valueatrisk covar offinancial institutions based on neural network quantile regression building onthe estimation results we model systemic risk spillover effects across banks byconsidering the marginal effects of the quantile regression procedure we adopt adropout regularization procedure to remedy the wellknown issue of overfittingfor neural networks and we provide empirical evidence for the favorable outofsample performance of a regularized neural network we then propose threemeasures for systemic risk from our fitted results we find that systemic riskincreases sharply during the height of the financial crisis in 2008 and againafter a short period of easing in 2011 and 2015 our approach also allowsidentifying systemically relevant firms during the financial crisiskeywordssystemic risk covar quantile regression neural networks sep abstractthe aim of this paper is to prove the phenotypic convergence ofcryptocurrencies in the sense that individual cryptocurrencies respond tosimilar selection pressures by developing similar characteristics in order toretrieve the cryptocurrencies phenotype we treat cryptocurrencies as financialinstruments genus proximum and find their specific difference differentia specifica by using the daily time series of logreturns in this sense a daily timeseries of asset returns either cryptocurrencies or classical assets can becharacterized by a multidimensional vector with statistical components likevolatility skewness kurtosis tail probability quantiles conditional tailexpectation or fractal dimension by using dimension reduction techniquesfactor analysis and classification models binary logistic regressiondiscriminant analysis support vector machines kmeans clustering variancecomponents split methods for a representative sample of cryptocurrenciesstocks exchange rates and commodities we are able to classify cryptocurrenciesas a new asset class with unique features in the tails of the logreturnsdistribution the main result of our paper is the complete separation of thecryptocurrencies from the other type of assets by using the maximum variancecomponents split method more we observe a divergent evolution of thecryptocurrencies species compared to the classical assets mainly due to thetails behaviour of the logreturns distribution the codes used here areavailable via wwwquantletdekeywordscryptocurrency genus proximum differentia specifica classificationmultivariate analysis factor models phenotypic convergence divergentevolution sep abstractthe paper presents a systematic theory for asymptotic inferences based onautocovariances of stationary processes we consider nonparametric tests for serial correlations using the maximum and the quadratic deviations of sampleautocovariances for these cases with proper centering and rescaling theasymptotic distributions of the deviations are gumbel and gaussian respectively to establish such an asymptotic theory as byproducts we develop anormal comparison principle and propose a sufficient condition for summabilityof joint cumulants of stationary processes we adapt a blocks of blocksbootstrapping procedure proposed by kuensch 1989 and liu and singh 1992 tothe maximum deviation based tests to improve the finitesample performancekeywordsautocovariance blocks of blocks bootstrapping boxpierce test extreme valuedistribution moderate deviation normal comparison physical dependencemeasure short range dependence stationary process summability of cumulants sep abstractthe 2017 bubble on the cryptocurrency market recalls our memory in the dotcombubble during which hardtomeasure fundamentals and investors illusion forbrand new technologies led to overvalued prices benefiting from the massiveincrease in the volume of messages published on social media and message boardswe examine the impact of investor sentiment conditional on bubble regimes oncryptocurrencies aggregate return prediction constructing a cryptospecificlexicon and using a localmomentum autoregression model we find that thesentiment effect is prolonged and sustained during the bubble while it turns outa reversal effect once the bubble collapsed the outofsample analysis alongwith portfolio analysis is conducted in this study when measuring investorsentiment for a new type of asset such as cryptocurrencies we highlight thatthe impact of investor sentiment on cryptocurrency returns is conditional onbubble regimeskeywordscryptocurrency sentiment bubble return predictability sep abstractwe distill tone from a huge assortment of nasdaq articles to examine thepredictive power of mediaexpressed tone in singlestock option markets andequity markets we find that 1 option markets are impacted by media tone 2option variables predict stock returns along with tone 3 option variablesorthogonalized to public information and tone are more effective predictors ofstock returns 4 overnight tone appears to be more informative than tradingtime tone possibly due to a different thematic coverage of the trading versusthe overnight archive 5 tone disagreement commands a strong positive riskpremium above and beyond market volatilitykeywordsoption markets equity markets stock return predictability media tone topicmodel sep abstractincreasingly volatile and distributed energy production challenge traditionalmechanisms to manage grid loads and price energy local energy markets lemsmay be a response to those challenges as they can balance energy production andconsumption locally and may lower energy costs for consumers blockchainbasedlems provide a decentralized market to local energy consumer and prosumers theyimplement a market mechanism in the form of a smart contract without the needfor a central authority coordinating the market recently proposed blockchainbased lems use auction designs to match future demand and supply thus suchblockchainbased lems rely on accurate shortterm forecasts of individualhouseholds energy consumption and production often such accurate forecastsare simply assumed to be given the present research tests this assumptionfirst by evaluating the forecast accuracy achievable with stateoftheartenergy forecasting techniques for individual households and second byassessing the effect of prediction errors on market outcomes in three differentsupply scenarios the evaluation shows that although a lasso regression modelis capable of achieving reasonably low forecasting errors the costly settlementof prediction errors can offset and even surpass the savings brought toconsumers by a blockchainbased lem this shows that due to prediction errorsparticipation in lems may be uneconomical for consumers and thus has to betaken into consideration for pricing mechanisms in blockchainbased lemskeywordsblockchain local energy market smart contract machine learning householdenergy prediction prediction errors market mechanism sep abstractwe consider a new procedure for detecting structural breaks in mean for highdimensional time series we target breaks happening at unknown time points andlocations in particular at a fixed time point our method is concerned witheither the biggest break in one location or aggregating simultaneous breaks overmultiple locations we allow for both big or small sized breaks so that we ca stamp the dates and the locations of the breaks 2 estimate the breaksizes and 3 make inference on the break sizes as well as the break dates ourtheoretical setup incorporates both temporal and crosssectional dependence andis suitable for heavytailed innovations we derive the asymptotic distributionfor the sizes of the breaks by extending the existing powerful theory on locallinear kernel estimation and high dimensional gaussian approximation to allowfor trend stationary time series with jumps a robust longrun covariance matrixestimation is proposed which can be of independent interest an application ondetecting structural changes of the us unemployment rate is considered toillustrate the usefulness of our methodkeywordshighdimensional time series multiple changepoints gaussian approximationnonparametric estimation heavy tailed longrun covariance matrix sep abstractin this paper we build an overlapping generation model to examine the reasonwhy developed countries with similar background have implemented differentsocial health insurance systems we propose two hypotheses to explain thisphenomenon i the different participation rates of the poor in the votingii the distinct attitudes towards the size of the government and the existenceof a compulsory social health insurance system agents need to vote for one oftwo policies policy i without social health insurance shi but with thesubsidy for the poor and policy ii with fully covered shi by comparing eithertheir current utility or the expected life time utility households will chooseone policy we find that under policy i the derivative of the changes ofexpected utility with respect to income is not monotonic this means that boththe poorest and the richest dislike the social health insurance system with thecalibrated parameters we solve the benchmark and find that the publicsattitude towards the size of the government and the lower representation of thepoor affect the election result the changes in the minimum consumption levelunder policy i affect the voting results most followed by the attitude votingparticipant rate plays the most insignificant role in the voting outcome thesensitivity analysis shows that our main findings are robust to the inputparameterskeywordssocial health insurance voting sep abstractin this paper we develop an multi period overlapping generation framework toinvestigate agents consumption and saving decisions inequality and welfareamong elderly we assume that agents are heterogeneous in the nonasset incomeand the medical expenditure in order to explicitly analyze the e ects ofmedical expenditure we conduct three counterfactual exercises we successivelyshut down the heterogeneity in labor income in the level and in the dispersionof medical expenses respectively by comparing the benchmark with thecounterfactual results we  nd that in general wealth inequality decreases withage and income uncertainty contributes the most to wealth inequality bothaverage consumption and consumption inequality increase with age consumptioninequality largely tracks income inequality though uncertainty in medicalexpenditures has little e ect on consumption inequality a higher level ofmedical expenditures may exacerbate consumption inequality meanwhile theaverage saving of elderly exhibits an inverseu shape with age the impacts onaverage saving are similar both in benchmark and in counterfactual exerciseswelfare increases with agekeywordsincome inequality social mobility pricetorent ratio sep abstracthousing typically takes up a major proportion of households expenditure andthus it certainly plays a critical role in shaping the pattern of income inequality and social mobility whether high housing pricetorent ratio will amplify inequality and inhibit social class upgrading is still a controversialissue in the existing literature in this paper we develop a partialequilibrium life cycle framework to address these issues agents in our economyare divided into two social classes according to the initial human capital levelinherited from their parents those who belong to upper class will draw theirinnate abilities from a distribution that  rst order stochastically dominatesthose from lower class throughout the entire lifecycle agents make endogenoushuman capital investment and housing tenure decisions we calibrate the model tomimic some stylized facts in the the real world counter part our simulationresults indicate an inverseu pattern between housing pricetorent ratio andmeasures of income inequality and as well as a ushape pattern between pricetorent ratio and social mobility measured by shorrocks index the implicationis that housing tends to amplify the inequality and slow down the socialmobility when houses can only be purchased by a small group of agents in theeconomy moreover our results also suggest that better quality of education asa result of a higher return to human capital investment tends to dampen the roleof housingkeywordsincome inequality social mobility pricetorent ratio sep abstractcryptocurrencies are becoming an attractive asset class and are the focus ofrecent quantitative research the joint dynamics of the cryptocurrency marketyields information on network risk utilizing the adaptive lasso approach webuild a dynamic network of cryptocurrencies and model the latent communitieswith a dynamic stochastic blockmodel we develop a dynamic covariateassistedspectral clustering method to uniformly estimate the latent group membership ofcryptocurrencies consistently we show that return interpredictability andcrypto characteristics including hashing algorithms and proof types jointlydetermine the crypto market segmentation based on this classification resultit is natural to employ eigenvector centrality to identify a cryptocurrencysidiosyncratic risk an asset pricing analysis finds that a crosssectionalportfolio with a higher centrality earns a higher risk premium further testsconfirm that centrality serves as a risk factor well and delivers valuableinformation content on cryptocurrency marketskeywordscommunity detection dynamic stochastic blockmodel spectral clustering nodecovariate return predictability portfolio management sep abstractdeep learning has substantially advanced the stateoftheart in computervision natural language processing and other  elds the paper examines thepotential of contemporary recurrent deep learning architectures for  nancialtime series forecasting considering the foreign exchange market as testbed wesystematically compare long shortterm memory networks and gated recurrent unitsto traditional recurrent architectures as well as feedforward networks in termsof their directional forecasting accuracy and the profitability of trading modelpredictions empirical results indicate the suitability of deep networks forexchange rate forecasting in general but also evidence the diculty ofimplementing and tuning corresponding architectures especially with regard totrading pro t a simpler neural network may perform as well as if not betterthan a more complex deep neural networkkeywordsdeep learning financial time series forecasting recurrent neural networksforeign exchange rates sep abstractrisk transmission among financial markets and their participants is timeevolving especially for the extreme risk scenarios possibly sudden timevariation of such risk structures ask for quantitative technology that is ableto cope with such situations here we present a novel localized multivariatecaviartype model to respond to the challenge of timevarying risk contagionfor this purpose a local adaptive approach determines homogeneous low riskvariation intervals at each time point critical values for this technique arecalculated via multiplier bootstrap and the statistical properties of thislocalized multivariate caviar are derived a comprehensive simulation studysupports the effectiveness of our approach in detecting structural change inmultivariate caviar finally when applying for the us and german financialmarkets we can trace out the dynamic tail risk spillovers and find that the usmarket appears to play dominate role in risk transmissions especially involatile market periodskeywordsconditional quantile autoregression local parametric approach change pointdetection multiplier bootstrap sep abstractunderstanding the topological structure of real world networks is of hugeinterest in a variety of fields one of the way to investigate this structure isto find the groups of densely connected nodes called communities this paperpresents a new nonparametric method of community detection in networks calledadaptive weights community detection the idea of the algorithm is to associatea local community for each node on every iteration the algorithm tests ahypothesis that two nodes are in the same community by comparing their localcommunities the test rejects the hypothesis if the density of edges betweenthese two local communities is lower than the density inside each one adetailed performance analysis of the method shows its dominance over stateoftheart methods on well known artificial and real world benchmarkskeywordsadaptive weights gap coefficient graph clustering nonparametric overlappingcommunities sep abstractsoftwareasaservice applications are experiencing immense growth as theircomparatively low cost makes them an important alternative to traditionalsoftware following the initial adoption phase vendors are now concerned withthe continued usage of their software to analyze the influence of differentmeasures to improve continued usage over time a longitudinal study design usingdata from a saas vendor was implemented by employing a linear mixed model thestudy finds several measures to have a positive effect on a softwares usagepenetration in addition to these activation measures performed by the saasvendor software as well as client characteristics were likewise examined butdid not display significant estimates in summary the study contributes novelinsights into the scarcely researched field of influencing factors on saas usagecontinuancekeywordslinear mixed models softwareasaservice usage continuance sep abstractthis paper provides a detailed framework for modeling portfolios achieving thehighest growth rate under subjective risk constraints such as value at riskvar in the presence of stable laws although the maximization of the expectedlogarithm of wealth induces outperforming any other significantly differentstrategy the kelly criterion implies larger bets than a riskaverse investorwould accept restricting the kelly optimization by spectral risk measures theauthors provide a generalized mapping for different measures of growth andsecurity analyzing over 30 years of sp 500 returns for different samplingfrequencies the authors find evidence for leptokurtic behavior for allrespective sampling frequencies given that lower sampling frequencies imply asmaller number of data points this paper argues in favor of stable laws andits scaling behavior to model financial market returns for a given horizon in aniid world instead of simulating from the class of elliptically stabledistributions a nonparametric scaling approximation based on the datasetitself is proposed our paper also uncovers that including long put optionsinto the portfolio optimization improves the growth criterion for a givensecurity level leading to a new kelly portfolio providing the highest geometricmeankeywordsgrowthoptimal kelly criterion protective put portfolio optimization stabledistribution value at risk sep abstractweekly quarterly and yearly risk measures are crucial for risk reportingaccording to basel iii and solvency ii for the respective data frequencies theauthors show in a simulation and backtest study that available data series arenot sufficient in order to estimate value at risk and expected shortfallsufficiently given confidence levels of 999 and 9999 accordingly thispaper presents a semiparametric estimation method rescaling data from high tolowfrequency which allows to obtain significantly more data points for theestimation of the respective risk measures the presented methodology in thestable framework which is able to mimic multifractal behavior in assetreturns provides tail events which never occurred in the original lowfrequencydatasetkeywordshighfrequency multifractal stable distribution rescaling risk managementvalue at risk quantile distribution sep abstractthis work aims to investigate the interrelations of information arrival newssentiment volatilities and jump dynamics of intraday returns two parametricgarchtype jump models which explicitly incorporate both news arrival and newssentiment variables are proposed among which one assumes news affectingfinancial markets through the jump component while the other postulating thegarch component channel in order to give the mostlikely format of theinteractions between news arrival and stock market behaviors these two modelsare compared with several other easier versions of garchtype models based onthe calibration results on djia 30 stocks the necessity to include newsprocesses in intraday stock volatility modeling is justified in our specificcalibration samples 2008 and 2013 respectively while it is not as profitableto model jump process separately as using simpler garch process with errordistribution capable to capture fat tail behaviors of financial time series inconclusion our calibration results suggest garchnews model with skewtinnovation distribution as the best candidate for intraday returns of largestocks in us market which means one can probably avoid the complicatedness ofmodelling jump behavior by using a simplier skewt error distribution assumptioninstead but its necessary to incorporate news variableskeywordsinformation arrival volatility modeling jump sentiment garch sep abstractexcessive house price growth was at the heart of the financial crisis i0708 since then many countries have added cooling measures to theirregulatory frameworks it has been found that these measures can indeed controlprice growth but no one has examined whether this has adverse consequences forthe housing wealth distribution we examine this for singapore which started i09 to target price growth over ten rounds in total we find that welfare fromhousing wealth in the last round might not be higher than before 2009 thisdepends on the deflator used to convert nominal into real prices irrespectiveof the deflator we can reject that welfare increased monotonically over thedifferent roundskeywordshouse price distribution stochastic dominance tests sep abstractwe study investor sentiment on a nonclassical asset cryptocurrencies using acryptospecificlexicon recently proposed in chen et al 2018 and statisticallearning methodswe account for contextspecific information and word similarityby learning word embeddingsvia neural networkbased worvec model on top ofpretrained word vectors weapply popular machine learning methods such asrecursive neural networks for sentencelevelclassification and sentiment indexconstruction we perform this analysis on a noveldataset of 1220k messagesrelated to 425 cryptocurrencies posted on a microblogging platformstocktwitsduring the period between march 2013 and may 2018 the constructed sentimentindices are valuerelevant in terms of its return and volatility predictabilityfor thecryptocurrency market indexkeywordssentiment analysis lexicon social media word embedding deep learning sep abstractsecondhand car markets contribute to billions of euro turnover each year buthardly generate profit for used car dealers the paper examines the potential ofsophisticated datadriven pricing systems to enhance supplierside decisionmaking and escape the zeroprofittrap profit maximization requires an accurateunderstanding of demand the paper identifies factors that characterize consumerdemand and proposes a framework to estimate demand functions using survivalanalysis empirical analysis of a large data set of daily used car sales betwee08 to 2012 confirm the merit of the new factors observed results also showthe value of survival analysis to explain and predict demand random survivalforest emerges as the most suitable vehicle to develop price response functionsas input for a dynamic pricing systemkeywordsautomotive industry price optimization survival analysis dynamic pricing sep abstract a copula model with flexibly specified dependence structure can be useful to capture the complexity and heterogeneity in economic and financial time series however there exists little methodological guidance for the specification process using copulas this paper contributes to fill this gap by considering the recently proposed singleindex copulas for which we propose a simultaneous estimation and variable selection procedure the proposed method allows to choose the most relevant state variables from a comprehensive set using a penalized estimation and we derive its large sample properties simulation results demonstrate the good performance of the proposed method in selecting the appropriate state variables and estimating the unknown index coefficients and dependence parameters an application of the new procedure identifies six macroeconomic driving factors for the dependence among us housing markets  keywordssemiparametric copula singleindex copula variable selection scad   sep abstract the estimation of a causal parameter in a highdimensional setting where the functions are potentially complex is a challenging task parametric and linear modelling is not sufficient to generate unbiased and consistent estimators modern approaches therefore use machine learning ml algorithms to learn these nuisance functions however this leads to new problems like the regularization bias or overfitting that are common when using ml models this paper considers different novel methods that overcome these problems or at least address them these methods differ in terms of the target parameter namely the average treatment effect of the population group heterogeneity or the conditional average treatment effect for each individual each method is first investigated and tested separately and second they are compared among each other to do this in a disciplined manner simulations with synthetic data are used this ensures that all distributions of the generated treatment effect parameters are known the findings are that each method has its limits in terms of unbiased estimation the detection of heterogeneity and also the determination of which covariates are responsible for different causal effects  keywords  causal inference machine learning simulation study samplesplitting double machine learning sorted group ate gates causal tree   sep abstract uplift modeling combines machine learning and experimental strategies to estimate the differential effect of a treatment on individuals behavior the paper considers uplift models in the scope of marketing campaign targeting literature on uplift modeling strategies is fragmented across academic disciplines and lacks an overarching empirical comparison using data from online retailers we fill this gap and contribute to literature through consolidating prior work on uplift modeling and systematically comparing the predictive performance and utility of available uplift modeling strategies our empirical study includes three experiments in which we examine the interaction between an uplift modeling strategy and the underlying machine learning algorithm to implement the strategy quantify model performance in terms of business value and demonstrate the advantages of uplift models over response models which are widely used in marketing the results facilitate making specific recommendations how to deploy uplift models in ecommerce applications  keywords  ecommerce analytics machine learning uplift modeling realtime targeting   sep abstract in deconvolution in rd d  1 with mixing density p2 p and kernel h the mixture density fp2 fp can always be estimated with fpn pn 2 p via minimum distance estimation approaches proposed herein with calculation of fpns upper error rate an in probability or in risk h is either known or unknown an decreases to zero with n in applications an is obtained when p consists either of products of d densities dened on a compact or  separable densities in r with their dierences changing sign at most j times j is either known or unknown when h is known and p is qsmooth vanishing outside a compact in rd plugin upper bounds are then also provided for the error rate of pn and its derivatives respectively in probability or in risk q 2 r d  1 these upper bounds depend on hs fourier transform h6 0 and have rates log a1 n  and a n  respectively for h supersmooth and smooth   0   0 for the typical an  log n  n the former logarithmic rate bound is optimal for any   0 and the latter misses the optimal rate by the factor log n when   5   0   0 the exponents  and  appear also in optimal rates and lower error and risk bounds in the deconvolution literature  keywords     sep abstract in linear regression of y on x2 rp with parameters 2 rp1 statistical inference is unreliable when observations are obtained from grosserror model fg  1f g instead of the assumed probability fg is grosserror probability 0    1 when g is unit mass at x y residuals in uence index rinfinx y   measures the dierence in small xperturbations of residual rx y for model f and for fg via rs xpartial derivatives asymptotic properties are presented for sample rinfin that is successful in extracting indications for in uential and bad leverage cases in microarray data and simulated high dimensional data its performance improves as p increases and can also be used in multiple response linear regression rinfins advantage is that whereas in in uence functions of regression coecients each xcoordinate and rx y appear in a sum as product with moderate size when x y is bad leverage case and masking makes rx y nearly vanish rinfins xpartial derivatives convert the product in sum allowing for unmasking  keywords  big data data science in fluence function leverage masking residuals in fluence index rinfin   sep abstract highdimensional streaming datasets are ubiquitous in modern applications examples range from nance and ecommerce to the study of biomedical and neuroimaging data as a result many novel algorithms have been proposed to address challenges posed by such datasets in this work we focus on the use of  regularized linear models in the context of possibly nonstationary streaming data recently it has been noted that the choice of the regularization parameter is fundamental in such models and several methods have been proposed which iteratively tune such a parameter in a timevarying manner thereby allowing the underlying sparsity of estimated models to vary moreover in many applications inference on the regularization parameter may itself be of interest as such a parameter is related to the underlying sparsity of the model however in this work we highlight and provide extensive empirical evidence regarding how various often unrelated statistical properties in the data can lead to changes in the regularization parameter in particular through various synthetic experiments we demonstrate that changes in the regularization parameter may be driven by changes in the true underlying sparsity signaltonoise ratio or even model misspecication the purpose of this letter is therefore to highlight and catalog various statistical properties which induce changes in the associated regularization parameter we conclude by presenting two applications one relating to nancial data and another to neuroimaging data where the aforementioned discussion is relevant  keywords  lasso penalty parameter stock prices neuroimaging   sep abstract the market capitalization of cryptocurrencies has risen rapidly during the last few years despite their high volatility this fact has spurred growing interest in cryptocurrencies as an alternative investment asset for portfolio and risk management we characterise the effects of adding cryptocurrencies in addition to traditional assets to the set of eligible assets in portfolio management outofsample performance and diversification benefits are studied for the most popular portfolioconstruction rules including meanvariance optimization riskparity and maximumdiversification strategies as well as combined strategies  to account for the frequently low liquidity of cryptocurrency markets we incorporate the libro method which gives suitable liquidity constraints our results show that cryptocurrencies can improve the riskreturn profile of portfolios in particular cryptocurrencies are more useful for portfolio strategies with higher target returns they do not play a role in minimumvariance portfolios however a maximumdiversification strategy maximising the portfolio diversification index pdi draws appreciably on cryptocurrencies and spanning tests clearly indicate that cryptocurrency returns are nonredundant additions to the investment universe  keywords  cryptocurrency crix investments portfolio management asset classes blockchain bitcoin altcoins dlt   sep abstract modeling the joint tails of multiple nancial time series has important im plications for risk management classical models for dependence often encounter a lack of t in the joint tails calling for additional  exibility in this paper we introduce a new nonparametric timevarying mixture copula model in which both weights and depen dence parameters are deterministic functions of time we propose penalized trending mixture copula models with group smoothly clipped absolute deviation scad penal ty functions to do the estimation and copula selection simultaneously monte carlo simulation results suggest that the shrinkage estimation procedure performs well in s electing and estimating both constant and trending mixture copula models using the proposed model and method we analyze the evolution of the dependence among four international stock markets and nd substantial changes in the levels and patterns of the dependence in particular around crisis periods  keywords  copula timevarying copula mixture copula copula selection   sep abstract in this paper we investigate the statistical properties of cryptocurrencies by using alphastable distributions we also study the benefits of the metcalfes law the value of a network is proportional to the square of the number of connected users of the system for the evaluation of cryptocurrencies as the results showed a potential for herding behaviour we used lppl models to capture the behaviour of cryptocurrencies exchange rates during an endogenous bubble and to predict the most probable time of the regime switching  keywords  cryptocurrency bitcoin crix logperiodic power law metcalfes law stable distribution   sep abstract an extensive empirical literature documents a generally negative relation named the leverage effect between asset returns and changes of volatility it is more challenging to establish such a returnvolatility relationship for jumps in highfrequency data we propose new nonparametric methods to assess and test for a discontinuous leverage effect  ie a covariation between contemporaneous jumps in prices and volatility the methods are robust to market microstructure noise and build on a newly developed pricejump localization and estimation procedure our empirical investigation of six years of transaction data from 320 nasdaq firms displays no unconditional negative covariation between price and volatility cojumps we show however that there is a strong and significant discontinuous leverage effect if one conditions on the sign of price jumps and whether the price jumps are marketwide or idiosyncratic  keywords  highfrequency data market microstructure news impact marketwide jumps price jump volatility jump   sep abstract openended responses are widely used in market research studies processing of such responses requires laborintensive human coding this paper focuses on unsupervised topic models and tests their ability to automate the analysis of openended responses since stateofthe art topic models struggle with the shortness of openended responses the paper considers three novel short text topic models latent feature latent dirichlet allocation biterm topic model and word network topic model the models are fitted and evaluated on a set of realworld openended responses provided by a market research company multiple components such as topic coherence and document classification are quantitatively and qualitatively evaluated to appraise whether topic models can replace human coding the results suggest that topic models are a viable alternative for openended response coding however their usefulness is limited when a correct onetoone mapping of responses and topics or the exact topic distribution is needed  keywords  market research openended responses text analytics short text topic models   sep abstract this paper studies the shortrun impacts of temperature on human performance in the computermediated environment using server logs of a popular online game in china taking advantage of the quasiexperiment of winter central heating policy inchina we distinguish the impacts of outdoor and indoor temperature and find that low temperatures below 5 c decrease game performance significantly nonexperienced players suffered larger performance drop than experienced ones access to central heating attenuates negative impacts of low outdoor temperatures on gamers performance high temperatures above 21 c also lead to drops in game performancewe conclude that expanding the current central heating zone will bring an increase in human performance by approximately 4 in shanghai and surrounding provinces in the winter while often perceived as a leisure activity online gaming requires intense engagement and the deployment of cognitive social and motor skills which are also key skills for productive activities our results draw attention to potential damages of extreme temperature on human performance in the modern computermediated environment  keywords  temperature human performance online game heating   sep abstract in this article we study a nonparametric approach regarding a general nonlinear reduced form equation to achieve a better approximation of the optimal instrument accordingly we propose the nonparametric additive instrumental variable estimator naive with the adaptive group lassowe theoretically demonstrate that the proposed estimator is rootn consistent and asymptotically normal the adaptive group lasso helps us select the valid instruments while the dimensionality of potential instrumental variables is allowed to be greater than the sample size in practice the degree and knots of bspline series are selected by minimizing the bic or ebic criteria for each nonparametric additive component in the reduced form equation in monte carlo simulations we show that the naive has the same performance as the linear instrumental variable iv estimator for the truly linear reduced form equation on the other hand the naive performs much better in terms of bias and mean squared errors compared to other alternative estimators under the highdimensional nonlinear reduced form equation we further illustrate our method in an empirical study of international trade and growth our findings provide  keywords  adaptive group lasso instrumental variables nonparametric additive model optimal estimator variable selection   sep abstract the conventional wisdom that housing prices are the present value of future rents ignores the fact that unlike dividends on stocks rent is not discretionary housing price uncertainty can affect household property investments which in turn affect rent by extending the theory of investment under uncertainty we model the renters decision to buy a house and the landlords decision to sell as the exercising of real options of waiting and examine real options effects on rent using data from hong kong and mainland china we find a significant effect of housing price on rent and draw important policy implications  keywords     sep abstract this paper is concerned with selecting important covariates and estimating the index direction simultaneously for high dimensional singleindex models we develop an efficient threshold gradient directed regularization method via maximizing distance covariance dctgdr between the single index and response variable due to the appealing property of distance covariance which can measure nonlinear dependence between random variables the proposed method avoids estimating the unknown link function of the single index and dramatically reduces computational complexity compared to other methods that use smoothing techniques it keeps the modelfree advantage from the view of sufficient dimension reduction and requires neither predictors nor response variable to be continuous in addition the dctgdr method encourages a grouping effect that is it is capable of choosing highly correlated covariates in or out of the model together we examine finitesample performance of the proposed method by monte carlo simulations in a real data analysis we identify important copy number alterations cnas for gene expression  keywords  distance covariance highdimensional data threshold gradient directed regularization singleindex models variable selection   sep abstract in this article we develop a tractable procedure for testing strict stationarity in a double autoregressive model and formulate the problem as testing if the top lyapunov exponent is negative without strict stationarity assumption we construct a consistent estimator of the associated top lyapunov exponent and employ a random weighting approach for its variance estimation which in turn are used in a ttype test we also propose a glad estimation for parameters of interest relaxing key assumptions on the commonly used qmle all estimators except for the intercept are shown to be consistent and asymptotically normal in both stationary and explosive situations the nitesample performance of the proposed procedures is evaluated via monte carlo simulation studies and a real dataset of interest rates is analyzed  keywords  dar model glad estimation nonstationarity random weighting strict stationarity testing   sep abstract in this paper we propose a new class of regime shift models with flexible switching mechanism that relies on a nonparametric probability function of the observed threshold variables the proposed models generally embrace traditional threshold models with contaminated threshold variables or heterogeneous threshold values thus gaining more power in handling complicated data structure we solve the identification issue by imposing either global shape restriction or boundary condition on the nonparametric probability function we utilize the natural connection between penalized splines and hierarchical bayes to conduct smoothing by adopting different priors our procedure could work well for estimations of smooth curve as well as discontinuous curves with occasionally structural breaks bayesian tests for the existence of threshold effects are also conducted based on the posterior samples from markov chain monte carlo mcmc methods both simulation studies and an empirical application in predicting the us stock market returns demonstrate the validity of our methods  keywords  threshold model nonparametric markov chain monte carlo bayesian inference spline   sep abstract in this article we propose a new class of semiparametric instrumental variable models with partially varying coefficients in which the structural function has a partially linear form and the impact of endogenous structural variables can vary over different levels of some exogenous variables we propose a threestep estimation procedure to estimate both functional and constant coefficients the consistency and asymptotic normality of these proposed estimators are established moreover a generalized ftest is developed to test whether the functional coefficients are of particular parametric forms with some underlying economic intuitions and furthermore the limiting distribution of the proposed generalized ftest statistic under the null hypothesis is established finally we illustrate the finite sample performance of our approach with simulations and two real data examples in economics  keywords  endogeneity functional coefficients generalized ftest instrumental variables models nonparametric test profile least squares   sep abstract we model the term structure of implied volatility tsiv with an adaptive approach to improve predictability which treats dynamic time series models of globally time varying but locally constant parameters and uses a datadriven procedure to nd the local optimal interval we choose two specications of the adaptive models a simple local ar lar model for a univariate implied volatility series and an adaptive dynamic nelsonsiegel adns model of three factors each based on an lar to model the cross section of the tsiv simultaneously with parsimony both lar and adns models uniformly outperform more than a dozen alternative models with signicance across maturities for 120 day forecast horizons measured by rmse and mae the forecast errors of the random walk model can be reduced by between 20 and 60 for the 5 to 20 days ahead forecast in terms of prediction accuracy of future directional changes the adaptive models achieve an accuracy range of 6090 which strictly dominates the range of 3059 of the alternative models  keywords  term structure of implied volatility local parametric models forecasting   sep abstract a trading rule that draws on the empirical similarity concept is proposed to simulate the technical trading mentalityone that selectively perceives structural resemblances between market scenarios of the present and the past in more than half of the nineteen futures markets that we test against for protability of this similaritybased trading rule we nd evidence of predictive ability that is robust to datasnooping and transactioncost adjust ments when aided by an exit strategy that liquidates the traders positions across some evenlyspaced time points this rule generates the most robust returns  keywords  empirical similarity technical trading futures markets analogical reasoning   sep abstract cryptocurrencies refer to a type of digital cash that use distributed ledger  or blockchain technology  to provide secure transactions these currencies are generally misunderstood while initially dismissed as fads or bubbles many large central banks are considering launching their own version of national cryptocurrencies in contrast to most data in nancial economics there is a plethora of detailed free data on the history of every transaction for the cryptocurrency complex further there is little empiricallyoriented research on this new asset class this is an extraordinary research opportunity for academia we provide a starting point by giving an insight into cryptocurrency mechanisms and detailing summary statistics and focusing on potential future research avenues in nancial economics  keywords  cryptocurrency blockchain bitcoin economic bubbles peertopeer cryptographic hashing consensus proofofwork proofofstake volatility   sep abstract news move markets and contains incremental information about stock reactions future trading volumes volatility and returns are a ected by sentiments of texts and opinions expressed in articles earlier work of sentiment distillation of stock news suggests that risk prole reactions might differ across sectors conventional asset pricing theory recognizes the role of a sector and its risk uniqueness that differs from market or rm specic risk our research assesses whether incorporating the sentiment distilled from sector specic news carries information about risk proles textual analytics applied to about 600k articles leads us with lexical projection and machine learning to classication of sentiment polarities the texts are scraped from offcial nasdaq web pages and with natural language processing nlp techniques such as tokenization lemmatization a sector specic sentiment is extracted using a lexical approach and a nancial phrase bank predicted sentencelevel polarities are aggregated into a bullishness measure on a daily basis and fed into a panel regression analysis with sector indicators supervised learning with hinge or logistic loss and regularization yields good prediction results of polarity compared with standard lexical projections the supervised learning approach yields superior predictions of sentiment leading to highly sector specic sentiment reactions the consumer staples health care and materials sectors show strong risk prole reactions to negative polarity  keywords  investor sentiment attention analysis sectorspecic reactions volatility text mining polarity   sep abstract in this paper the complete convergence for maximal weighted sums of extended negatively dependent end for short random variables is investigated some sucient conditions for the complete convergence and some applications to a nonparametric model are provided the results obtained in the paper generalise and improve the corresponding ones of wang el al 2014b and shen xue and wang 2017  keywords  complete convergence maximal weighted sums extended negatively dependent   sep abstract we consider a generalization of baumkatz theorem for random vari ables satisfying some cover conditions consequently we get the result for many dependent structure such as end mixing mixing and mixing etc  keywords  complete convergence marcinkiewiczzygmund type slln extended negatively dependent mixing dependency weakly mean bounded   sep abstract in this paper the complete convergence and complete moment convergence for maximal weighted sums of extended negatively dependent random variables are investigated some sucient conditions for the convergence are provided in addition the marcinkiewiczzygmund type strong law of large numbers for weighted sums of extended negatively dependent random variables is obtained the results obtained in the article extend the corresponding ones for independent random variables and some dependent random variables  keywords  extended negatively dependent complete convergence complete moment convergence maximal weighted sums strong law of large numbers   sep abstract in the present paper we propose a new method the penalized adaptive method pam for a data driven detection of structural changes in sparse linear models the method is able to allocate the longest homogeneous intervals over the data sample and simultaneously choose the most proper variables with the help of penalized regression models the method is simple yet  exible and can be safely applied in highdimensional cases with dierent sources of parameter changes comparing with the adaptive method in linear models its combination with dimension reduction yields a method which properly selects signicant variables and detects structural breaks while steadily reduces the forecast error in highdimensional data  keywords  scad penalty propagationseparation adaptive window choice multiplier bootstrap   sep abstract starting from wellknown empirical stylised facts of nancial time series we develop dynamic portfolio protection trading strategies based on econometric methods as a criterion for riskiness we consider the evolution of the valueatrisk spread from a garch model with normal innovations relative to a garch model with generalised innovations these generalised innovations may for example follow a student t a generalised hyperbolic gh an alphastable or a generalised pareto gpd distribution our results indicate that the gpd distribution provides the strongest signals for avoiding tail risks this is not surprising as the gpd distribution arises as a limit of tail behaviour in extreme value theory and therefore is especially suited to deal with tail risks outofsample backtests on 11 years of dax futures data indicate that the dynamic tailrisk protection strategy eectively reduces the tail risk while outperforming traditional portfolio protection strategies the results are further validated by calculating the statistical signicance of the results obtained using bootstrap methods a number of robustness tests including application to other assets further underline the eectiveness of the strategy finally by empirically testing for second order stochastic dominance we nd that risk averse investors would be willing to pay a positive premium to move from a static buyandhold investment in the dax future to the tailrisk protection strategy  keywords  tailrisk protection portfolio protection extreme events tail distributions   sep abstract we investigate default probabilities and default correlations of mertontype credit portfolio models in stress scenarios where a common risk factor is truncated the analysis is performed in the class of elliptical distributions a family of lighttailed to heavytailed distributions encompassing many distributions commonly found in nancial modelling it turns out that the asymptotic limit of default probabilities and default correlations depend on the maxdomain of the elliptical distributions mixing variable in case the mixing variable is regularly varying default probabilities are strictly smaller than 1 and default correlations are in 0 1 both can be expressed in terms of the student tdistribution function in the rapidly varying case default probabilities are 1 and default correlations are 0 we compare our results to the tail dependence function and discuss implications for credit portfolio modelling   keywords  financial risk management credit portfolio modelling stress testing elliptic distribution maxdomain  msc classification  60 91 sep abstract paralleling regulatory developments we devise valueatrisk and expected shortfall type risk measures for the potential losses arising from using misspecied models when pricing and hedging contingent claims essentially losses from model risk correspond to losses realized on a perfectly hedged position model uncertainty is expressed by a set of pricing models relative to which potential losses are determined using market data a unied loss distribution is attained by weighing models according to a relative likelihood criterion examples demonstrate the magnitude of model risk and corresponding capital buers necessary to suciently protect trading book positions against unexpected losses from model risk   keywords  model risk parameter uncertainty hedge error valueatrisk expected shortfall  jel clasification   sep abstract we investigate correlations of asset returns in stress scenarios where a common risk factor is truncated our analysis is performed in the class of normal variance mixture nvm models which encompasses many distributions commonly used in nancial modelling for the special cases of jointly normally and tdistributed asset returns we derive closed formulas for the correlation under stress for the nvm distribution we calculate the asymptotic limit of the correlation under stress which depends on whether the variables are in the maximum domain of attraction of the frechet or gumbel distribution it turns out that correlations in heavytailed nvm models are less sensitive to stress than in medium or lighttailed models our analysis sheds light on the suitability of this model class to serve as a quantitative framework for stress testing and as such provides valuable information for risk and capital management in nancial institutions where nvm models are frequently used for assessing capital adequacy we also demonstrate how our results can be applied for more prudent stress testing   keywords  stress testing risk management correlation normal variance mixture distribution multivariate normal distribution multivariate tdistribution sep abstract in 2012 jpmorgan accumulated a usd 62 billion loss on a credit derivatives portfolio the socalled london whale partly as a consequence of decorrelations of nonperfectly correlated positions that were supposed to hedge each other motivated by this case we devise a factor model for correlations that allows for scenariobased stresstesting of correlations we derive a number of analytical results related to a portfolio of homogeneous assets using the concept of mahalanobis distance we show how to identify adverse scenarios of correlation risk as an example we apply the factormodel approach to the london whale portfolio and determine the valueatrisk impact from correlation changes since our ndings are particularly relevant for large portfolios where even small correlation changes can have a large impact a further application would be to stresstest portfolios of central counterparties which are of systemically relevant size   keywords  correlation stress testing scenario selection market risk london whale  jel classication      sep abstract in a continuoustime setting where a riskaverse agent controls the drift of an output process driven by a brownian motion optimal contracts are linear in the terminal output this result is wellknown in a setting with moral hazard and  under stronger assumptions  adverse selection we show that this result continues to hold when in addition reser vation utilities are typedependent this type of problem occurs in the study of optimal compensation problems involving competing principals   keywords  principalagent modelling contract design stochastic process stochastic control sep abstract in this paper we study the latent group structure in cryptocurrencies market by forming a dynamic return inferred network with coin attributions we develop a dynamic covariateassisted spectral clustering method to detect the communities in dynamic network framework and prove its uniform consistency along the horizons applying our new method we show the return inferred network structure and coin attributions including algorithm and proof types jointly determine the market segmentation based on the network model we propose a novel hardtovalue measure using the centrality scores further analysis reveals that the group with a lower centrality score exhibits stronger shortterm return reversals crosssectional return predictability further conrms the economic meanings of our grouping results and reveal important portfolio management implications   keywords  community detection dynamic network return predictability behavioural bias market segmentation bitcoin sep abstract iv regression in the context of a resampling is considered in the work comparatively the contribution in the development is a structural identication in the iv model the work also contains a multiplierbootstrap justication   keywords  gaussian process kernel methods wasserstein distance  sep abstract in this work we propose to define gaussian processes indexed by multidimensional distributions in the framework where the distributions can be modeled as iid realizations of a measure on the set of distributions we prove that the kernel defined as the quadratic distance between the transportation maps that transport each distribution to the barycenter of the distributions provides a valid covariance function in this framework we study the asymptotic properties of this process proving micro ergodicity of the parameters   keywords  gaussian process kernel methods wasserstein distance   sep abstract we consider a problem of multiclass classification where the training sample sn  xi yin i1 is generated from the model py  mx  x  mx 1 6 m 6 m and 1x     mx are unknown lip schitz functions given a test point x our goal is to estimate 1x     mx an approach based on nonparametric smoothing uses a localization technique ie the weight of observation xi yi depends on the distance between xi and x however local estimates strongly depend on localiz ing scheme in our solution we fix several schemes     wk compute corresponding local estimates e1     ek for each of them and apply an aggregation procedure we propose an algorithm which constructs a con vex combination of the estimates e1     ek such that the aggregated estimate behaves approximately as well as the best one from the collection e1     ek we also study theoretical properties of the procedure prove oracle results and establish rates of convergence under mild assumptions   keywords     sep abstract in the work a characterization of difference of multivariate gaussian measures is found on the family of centered eucledian balls in particular it helps to derive xx see paper   keywords  multivariate gaussian measure kolmogorov distance gaussian comparison   sep abstract let     xn be iid sample in rp with zero mean and the covariance matrix   the classic principal component analysis esti mates the projector p j onto the direct sum of some eigenspaces of  by its empirical counterpart bpj  recent papers 20 23 investigate the asymptotic distribution of the frobenius distance between the projectors k bpj p j   the problem arises when one tries to build a condence set for the true projector eectively we consider the problem from bayesian perspective and derive an approximation for the posterior distribution of the frobenius distance between projectors the derived theorems hold true for nongaussian data the only assumption that we impose is the con centration of the sample covariance b in a vicinity of   the obtained results are applied to construction of sharp condence sets for the true pro jector numerical simulations illustrate good performance of the proposed procedure even on nongaussian data in quite challenging regime   keywords  covariance matrix spectral projector principal component analysis bernstein  von mises theorem   sep abstract in this paper we consider a probabilistic setting where the probability measures are considered to be random objects we propose a procedure of construction nonasymptotic confidence sets for empirical barycenters in 2 wasserstein space and develop the idea further to construction of a nonparametric twosample test that is then applied to the detection of structural breaks in data with complex geometry both procedures mainly rely on the idea of multiplier bootstrap spokoiny and zhilova 29 chernozhukov chetverikov and kato 13 the main focus lies on probability measures that have commuting covariance matrices and belong to the same scatterlocation family we proof the validity of a bootstrap procedure that allows to compute confidence sets and critical values for a wassersteinbased twosample test   keywords  wasserstein barycenters hypothesis testing multiplier bootstrap change point detection confidence sets   sep abstract let     xn be iid sample in rp with zero mean and the covariance matrix  the problem of recovering the projector onto an eigenspace of  from these observations naturally arises in many applications recent technique from 9 helps to study the asymp totic distribution of the distance in the frobenius norm kpr  bp r between the true projector pr on the subspace of the rth eigenvalue and its empirical counterpart bp r in terms of the effective rank of  this paper offers a bootstrap procedure for building sharp confidence sets for the true projector pr from the given data this procedure does not rely on the asymptotic distribution of kpr  bp r and its moments it could be applied for small or moderate sample size n and large dimension p the main result states the validity of the proposed procedure for finite samples with an explicit error bound for the er ror of bootstrap approximation this bound involves some new sharp results on gaussian comparison and gaussian anticoncentration in highdimensional spaces numeric results confirm a good performance of the method in realistic examples   keywords     sep abstract we distill sentiment from a huge assortment of nasdaq news articles by means of machine learning methods and examine its predictive power in singlestock option markets and equity markets we provide evidence that singlestock options react to contemporaneous sentiment next examining return predictability we discover that while option variables indeed predict stock returns sentiment variables add further informational content in fact both in a regression and a trading context option variables orthogonalized to public and sentimental news are even more informative predictors of stock returns distinguishing further between overnight and tradingtime news we find the first to be more informative from a statistical topic model we uncover that this is attributable to the differing thematic coverage of the alternate archives finally we show that sentiment disagreement commands a strong positive risk premium above and beyond market volatility and that lagged returns predict future returns in concentrated sentiment environments   keywords  investor disagreement option markets overnight information stock return predictability textual sentiment topic model tradingtime information   sep abstract the new keynesian theory of inflation determination has been under scrutiny due to identification issues which rather have to do with the mechanism of inflation determination at its core ie cochrane 2011 moreover similar identification problems arise in the case of fiscal inflation see for example leeper and leith 2016 leeper and li 2017 and leeper and walker 2012 this paper makes a positive contribution we argue that statements about observational equivalence stem from referring to the equilibrium path while this should not be our primary source of identifying restrictions moreover policy identification or lack thereof relies on assumptions on the underlying shock structure which is unobservable we instead extract shocks using heterogeneous uncertain restrictions and external datasets that is we learn from errors we are then able to recover deep and policy parameters irrespective of the prevailing equilibrium we provide time varying evidence on the efficacy of policy in stabilizing the us economy and on the time varying plausibility of ricardian versus nonricardian price determination results are work in progress   keywords  monetary and fiscal policy price determination identification learning from errors   sep abstract we consider the estimation and inference in a system of highdimensional regression equations allowing for temporal and crosssectional dependency in covariates and error processes covering rather general forms of weak dependence a sequence of largescale regressions with lasso is applied to reduce the dimensionality and an overall penalty level is carefully chosen by a block multiplier bootstrap procedure to account for multiplicity of the equations and dependencies in the data correspondingly oracle properties with a jointly selected tuning parameter are derived we further provide highquality debiased simultaneous inference on the many target parameters of the system we provide bootstrap consistency results of the test procedure which are based on a general bahadur representation for the zestimators with dependent data simulations demonstrate good performance of the proposed inference procedure finally we apply the method to quantify spillover effects of textual sentiment indices in a financial market and to test the connectedness among sectors   keywords  lasso time series simultaneous inference system of equations zestimation bahadur representation martingale decomposition   sep abstract in this paper we propose a new class of regime shift models with  exible switching mechanism that relies on a nonparametric probability function of the observed thresh old variables the proposed models generally embrace traditional threshold models with contaminated threshold variables or heterogeneous threshold values thus gaining more power in handling complicated data structure we solve the identification issue by imposing either global shape restriction or boundary condition on the nonparametric probability function we utilize the natural connection between penalized splines and hierarchical bayes to conduct smoothing by adopting dierent priors our procedure could work well for estimations of smooth curve as well as discontinuous curves with occasionally structural breaks bayesian tests for the existence of threshold eects are also conducted based on the posterior samples from markov chain monte carlo m cmc methods both simulation studies and an empirical application in predicting the us stock market returns demonstrate the validity of our methods   keywords  threshold model nonparametric markov chain monte carlo bayesian inference spline   sep abstract given data y and k covariates xj one problem in linear regression is to decide which if any of the covariates to include when regressing the dependent variable y on the covariates xj  in this paper three such methods lasso knockoff and gaussian covariates are compared using simulations and real data the gaussian covariate method is based on exact probabilities which are valid for all y and xj making it model free moreover the probabilities agree with those based on the fdistribution for the standard linear model with iid gaussian errors it is conceptually mathematically and algorithmically very simple it is very fast and makes no use of simulations it outperforms lasso and knockoff in all respects by a considerable margin   keywords     sep abstract this paper presents a new approach to nonparametric cluster analysis called adaptive weights clustering awc the idea is to identify the clustering structure by checking at different points and for dierent scales on departure from local homogeneity the proposed procedure describes the clustering structure in terms of weights wij each of them measures the degree of local inhomogeneity for two neighbor local clusters using statistical tests of no gap between them the procedure starts from very local scale then the parameter of locality grows by some factor at each step the method is fully adaptive and does not require to specify the number of clusters or their structure the clustering results are not sensitive to noise and outliers the procedure is able to recover dierent clusters with sharp edges or manifold structure the method is scalable and computationally feasible an intensive numerical study shows a stateoftheart performance of the method in various articial examples and applications to text data our theoretical study states optimal sensitivity of awc to local inhomogeneity   keywords  adaptive weights clustering gap coecient manifold clustering   sep abstract we investigate the concept of connectedness which is important for risk measurement and management ingerman energy market understanding and learning from these mechanisms are essential to avoid future systemic disasters to deal with large portfolio selection we propose regularization approach to capture the spillover and contagion effects acrossgerman power derivatives this paper shows how network analysis can facilitate the monitoring of futures price movements our methodology combines highdimensional variable selection techniques with network analysis the results show that contracts like phelix base year options and phelix peak year futures are in the core of the energy futures market   keywords  regularization energy risk transmission network german energy market   sep abstract this paper analyzes the market impact of limit order books lob taking crossstock effects into account based on penalized vector autoregressive approach we aim to identify significance and magnitude of the directed network channels within and between lobs by bootstrapped impulse response functions moreover information on asymmetries and imbalances within the lob over time would be derived for the sample of a nasdaq bluechip portfolio during 06072016 we find that lob network effects crucially determine prices and bidask asymmetries are prevalent   keywords  limit order book high dimension generalized impulse response high frequency market risk market impact network bootstrap   sep abstract cryptocurrencies such as bitcoin are establishing themselves as an investment asset and are often named the new gold this study however shows that the two assets could barely be more dierent firstly we analyze and compare conditional variance properties of bitcoin and gold as well as other assets and nd dierences in their structure secondly we implement a bekkgarch model to estimate timevarying conditional correlations gold plays an important role in nancial markets with  ighttoquality in times of market distress our results show that bitcoin behaves as the exact opposite and it positively correlates with downward markets lastly we analyze the properties of bitcoin as portfolio component and nd no evidence for hedging capabilities we conclude that bitcoin and gold feature fundamentally dierent properties as assets and linkages to equity markets our results hold for the broad cryptocurrency index crix as of now bitcoin does not re ect any distinctive properties of gold other than asymmetric response in variance   keywords  bekk bitcoin crix cryptocurrency gold garch conditional correlation asymmetry long memory   sep abstract trading of bitcoin is spread about multiple venues where buying and selling is offered in various currencies however all markets trade one common good and by the law of one price the different prices should not deviate in the long run in this context we are interested in which platform is the most important one in terms of price discovery to this end we use a pairwise approach accounting for a potential impact of exchange rates the contribution to price discovery is measured by hasbroucks and gonzalo and grangers information share we then derive an ordering with respect to the importance of each market which reveals that the chinese okcoin platform is the leader in price discovery of bitcoin followed by btc china   keywords  price discovery bitcoin hasbrouck information shares   sep abstract data from social media has created opportunities to understand how and why people move through their urban environment and how this relates to criminal activity to aid resource allocation decisions in the scope of predictive policing the paper proposes an approach to predict weekly crime counts the novel approach captures spatial dependency of criminal activity through approximating human dynamics it integrates point of interest data in the form of foursquare venues with twitter activity and taxi trip data and introduces a set of approaches to create features from these data sources empirical results demonstrate the explanatory and predictive power of the novel features analysis of a sixmonth period of realworld crime data for the city of new york evidences that both temporal and static features are necessary to eectively account for human dynamics and predict crime counts accurately furthermore results provide new evidence into the underlying mechanisms of crime and give implications for crime analysis and intervention   keywords  predictive policing crime forecasting social media data spatial econometrics   sep abstract marketing messages are most effective if they reach the right customers deciding which customers to contact is thus an important task in campaign planning the paper focuses on empirical targeting models we argue that common practices to develop such models do not account sufficiently for business goals to remedy this we propose profitconscious ensemble selection a modeling framework that integrates statistical learning principles and business objectives in the form of campaign profit maximization the results of a comprehensive empirical study confirm the business value of the proposed approach in that it recommends substantially more profitable target groups than several benchmarks   keywords  marketing decision support business value profitanalytics machine learning   sep abstract new public management helps universities and research institutions to perform in a highly competitive research environment evaluating publicly financed research results improves transparency helps in reflection and selfassessment and provides information for strategic decision making in this paper we provide empirical evidence using data from a collaborative research centre crc on financial inputs and research output from 2005 to 2016 after selecting performance indicators suitable for a crc we describe main properties of the data using visualization techniques to study the relationship between the dimensions of research performance we use a time fixed effects panel data model and fixed effects poisson model with the help of year dummy variables we show how the pattern of research productivity changed over time after controlling for staff and travel costs the joint depiction of the time fixed effects and the research projects life cycle allows a better understanding of the development of the number of discussion papers over time   keywords  research performance time fixed effects panel data model fixed effects poisson model network collaborative research centre   sep abstract estimation or misspecification errors in the portfolio loss distribution can have a considerable impact on risk measures this paper investigates the sensitivity of tailrelated risk measures including the valueatrisk expected shortfall and the expectilequantile transformation level in an epsiloncontamination neighbourhood the findings give the different approximations via the tail heaviness of the contamination models and its contamination levels illustrating examples and an empirical study on the dynamic crix capturing and displaying the market movements are given the codes used to obtain the results in this paper are available via httpsgithubcomquantletsrmc   keywords  sensitivity expected shortfall expectile valueatrisk risk management influence function crix   sep abstract many southeast european countries are currently undergoing a process of liberalization of electric power markets the paper analyses dayahead price dynamics on some of these new markets and in germany as a benchmark of a completely decentralized western european market to that end several price forecasting methods including autoregressive approaches multiple linear regression and neural networks are considered these methods are tested on hourly dayahead price data during four twoweek periods corresponding to different seasons and varying levels of volatility in all selected markets the most influential fundamental factors are determined and performance of forecasting techniques is analysed with respect to the age of the market its degree of liberalization and the level of volatility a comparison of southeast european electricity markets of different age with the older german market is made and clusters of similar southeast european markets are identified   keywords  arima models energy forecasting time series models neural networks   sep abstract the recent emergence of blockchainbased cryptocurrencies has received a considerable attention the growing acceptance of cryptocurrencies has led many to speculate that the blockchain technology can surpass a traditional centralized monetary system however no monetary model has yet been de veloped to study the economics of the blockchain this paper builds a model of the economy with a single generally acepted blockchainbased currency in the spirit of the search and matching literature i use a matching function to model the operation of the blockchain the formulation of the money demand is taken from a workhorse of monetary economics  lagos and wright 2005 i show that in a blockchainbased monetary system money demand features a precautionary motive which is absent in the standard lagoswright model due to this precautionary money demand the monetary equilibrium can be stable for some calibrations i also used the developed model to study how the equilibrium return on money is  keywords  blockchain miners cryptocurrency matching function   sep abstract we link the hiring of rd scientists from industry competitors to the subsequent formation of collaborative agreements namely technologyoriented alliances by transferring technological knowledge as well as cognitive elements to the hiring firm mobile inventors foster the alignment of decision frames applied by potential alliance partners in the process of alliance formation thereby making collaboration more likely using data on inventor mobility and alliance formation amongst 42 global pharmaceutical firms over 16 years we show that inventor mobility is positively associated with the likelihood of alliance formation in periods following inventor movements this relationship becomes more pronounced if mobile employees bring additional knowledge about their prior firms technological capabilities and for alliances aimed at technology development rather than for agreements related to technology transfer it is weakened however if the focal firm is already familiar with the competitors technological capabilities by revealing these relationships our study contributes to research on alliance formation employee mobility and organizational frames   keywords    jel classication sep abstract the recent development of private cryptocurrencies has created a need to extend existing models of private currency provision and currency competi tion the outcome of cryptocurrency competition should be analyzed in a model which incorporates important features of the modern cryptocurren cies in this paper i focus on two such features first cryptocurrencies operate according to a protocol  a blockchain  and are therefore free from the timeinconsistency problem second the operation of the blockchain costs real resources i use the lagoswright search theoretic monetary model augmented with privately issued currencies as in fernandezvillaverde and sanches 2016 and extend it by linear costs of private currency circulation i show that in contrast to fernandezvillaverde and sanches 2016 cryptocur rency competition 1 does not deliver price stability and 2 puts downward pressure on the in ation in the public currency only when the costs private currency circulation mining costs are suciently low   keywords  currency competition cryptocurrency in ation blockchain  jel classication      sep testing for bubbles in cryptocurrencies with timevarying volatility christian m hafner abstract the recent evolution of cryptocurrencies has been characterized by bubblelike behavior and extreme volatility while it is difficult to assess an intrinsic value to a specific cryptocurrency one can employ recently proposed bubble tests that rely on recursive applications of classical unit root tests this paper extends this approach to the case where volatility is time varying assuming a deterministic longrun component that may take into account a decrease of unconditional volatility when the cryptocurrency matures with a higher market dissemination volatility also includes a stochastic shortrun component to capture volatility clustering the wild bootstrap is shown to correctly adjust the size properties of the bubble test which retains good power properties in an empirical application using eleven of the largest cryptocurrencies and the crix index the general evidence in favor of bubbles is confirmed but much less pronounced than under constant volatility keywords  cryptocurrencies speculative bubbles wild bootstrap volatility    sep abstract the crix cryptocurrency index has been constructed based on a number of cryptos and provides a high coverage of market liquidity huberlincrix the crypto currency market is a new asset market and attracts a lot of investors recently surprisingly a market for contingent claims hat not been built up yet a reason is certainly the lack of pricing tools that are based on solid financial econometric tools here a first step towards pricing of derivatives of this new asset class is presented after a careful econometric preanalysis we motivate an affine jump diffusion model ie the svcj stochastic volatility with correlated jumps model we calibrate svcj by mcmc and obtain interpretable jump processes and then via simulation price options the jumps present in the cryptocurrency fluctutations are an essential component concrete examples are given to establish an ocrix exchange platform trading options on crix   keywords  cryptocurrency index crix bitcoincryptocurrency svcj option pricingocrix sep abstract with optionimplied volatility indices we provide a new tool for event studies in a network setting and document systemic risk in the spillover networks across global financial markets network linkages are sufficiently asymmetric because the us stock and bond markets play as dominant volatility suppliers to other countries and markets shocks from the us generate systemic risk through intensifying volatility spillovers across countries and asset classes the findings offer new evidence that asymmetric network linkages can lead to sizable aggregate fluctuations and thus potential systemic risk   keywords  network optionimplied volatility spillover asymmetric linkage systemic risk sep abstract for multivariate nonparametric regression models existing variable selection methods with penalization require highdimensional nonparametric approximations in objective functions when the dimension is high none of methods with penalization in the literature are readily available also ranking and screening approaches cannot have selection consistency when iterative algorithms cannot be used due to inefficient nonparametric approximation in this paper a novel and easily implemented approach is proposed to make existing methods feasible for selection with no need of nonparametric approximation selection consistency can be achieved as an application to additive regression models we then suggest a twostage procedure that separates selection and estimation steps an adaptive estimation to the smoothness of underlying components can be constructed such that the consistency can be even at parametric rate if the underlying model is really parametric simulations are carried out to examine the performance of our method and a real data example is analyzed for illustration   keywords adaptive estimation nonparametric additive model purely nonparametric regression variable selection sep abstract appropriate risk management is crucial to ensure the competitiveness of financial institutions and the stability of the economy one widely used financial risk measure is valueatrisk var var estimates based on linear and parametric models can lead to biased results or even underestimation of risk due to time varying volatility skewness and leptokurtosis of nancial return series the paper proposes a nonlinear and nonparametric framework to forecast var mean and volatility are modeled via support vector regression svr where the volatility model is motivated by the standard generalized autoregressive conditional heteroscedasticity garch formulation based on this var is derived by applying kernel density estimation kde this approach allows for  exible tail shapes of the profit and loss distribution and adapts for a wide class of tail events the svrgarchkde hybrid is compared to standard exponential and threshold garch models coupled with different error distributions to examine the performance in different markets onedayahead forecasts are produced for different financial indices model evaluation using a likelihood ratio based test framework for interval forecasts indicates that the svrgarchkde hybrid performs competitive to benchmark models especially models that are coupled with a normal distribution are systematically outperformed   keywords valueatrisk support vector regression kernel density estimation garch sep  sep abstract highfrequency data can provide us with a quantity of informa tion for forecasting help to calculate and prevent the future risk based on extremes this tail behaviour is very often driven by ex ogenous components and may be modelled conditional on other vari ables however many of these phenomena are observed over time exhibiting nontrivial dynamics and dependencies we propose a func tional dynamic factor model to study the dynamics of expectile curves the complexity of the model and the number of dependent variables are reduced by lasso penalization the functional factors serve as a lowdimensional representation of the conditional tail event while the timevariation is captured by factor loadings we illustrate the model with an application to climatology where daily data over years on temperature rainfalls or strength of wind are available key words  factor model functional data expectiles extremes sep abstract for changepoint analysis of high dimensional time series we consider a semiparametric model with dynamic structural break factors the observations are described by a few low dimensional factors with timeinvariate loading functions of covariates the unknown structural break in time models the regime switching eects introduced by exogenous shocks in particular the factors are assumed to be nonstationary and follow a vector autoregression var process with a structural break in addition to account for the known spatial discrepancies we introduce discrete loading functions we study the theoretical properties of the estimates of the loading functions and the factors moreover we provide both the consistency and the asymptotic convergence results for making inference on the common breakpoint in time the estimation precision is evaluated via a simulation study finally we present two empirical illustrations on modeling the dynamics of the minimum wage policy in china and analyzing a limit order book dataset key words  high dimensional time series changepoint analysis temporal and crosssectional dependence vector autoregressive process sep abstract the eu emission trading system eu ets was created to reduce the c and other greenhouse gas emissions at the lowest economic cost in reality market participants are faced with considerable uncertainty due to price changes and require price and volatility estimates and forecasts for appropriate risk management asset allocation and volatility trading although the simplest approach to estimate volatility is to use the historical standard deviation realized volatility is a more accurate measure for volatility since it is based on intraday data besides the stylized facts commonly observed in financial time series we observe longmemory properties in the realized volatility series which motivates the use of heterogeneous autoregressive har class models therefore we propose to model and forecast the realized volatility of the eu ets futures with har class models the har models outperform benchmark models such as the standard longmemory arfima model in terms of model fit insample and outofsample forecasting the analysis is based on intraday data may 2007april 2012 for futures on c certificates for the second euets trading period expiry december 20082012 the estimation results of the models allow to explain the volatility drivers in the market and volatility structure according to the heterogeneous market hypothesis as well as the observed asymmetries we see that both speculators with short investment horizons as well as traders taking longterm hedging positions are active in the market in a simulation study we test the suitability of the har model for option pricing and conclude that the har model is capable of mimicking the longterm volatility structure in the futures market and can be used for shortterm and longterm option pricing key words  eu ets realized volatility har volatility forecasting intraday data c emission allowances emissions markets asymmetry shar harq mc simulation sep abstract this paper considers a fast and effective algorithm for conducting functional principle component analysis with multivariate factors compared with the univariate case our approach could be more powerful in revealing spatial connections or extracting important features in images to facilitate fast computation we connect singular value decomposition with penalized smoothing and avoid estimating a huge dimensional covariance operator under regularity assumptions the results indicate that we may enjoy the optimal convergence rate by employing the smoothness assumption inherent to functional objects we apply our method on the analysis of brain image data our extracted factors provide excellent recovery of the risk related regions of interests in human brain and the estimated loadings are very informative in revealing the individual risk attitude key words  principal component analysis penalized smoothing asymptotics functional magnetic resonance imaging fmri sep  sep abstract dem deutschen arbeitsmarkt ging es noch nie seit der wiedervereinigung so gut wie heute die nachhaltige entwicklung seit 2005 ist auf zwei entscheidende treiber zurckzufhren die umverteilung eines beinahe gleichbleibenden arbeitsstundenvolumens auf mehr beschftigte und die massive ausweitung der teilzeitarbeit die lohnzurckhaltung der tarifparteien war dabei eine notwendige jedoch nicht hinreichende bedingung fr diesen erfolg die kovarianz von lohn und erwerbsindikatoren deutet darauf hin dass die arbeitsmarktreformen der sogenannten agenda 2010 die erwerbsfhige bevlkerung ab 2005 zur teilnahme am arbeitsmarkt aktiviert haben insbesondere die reform der arbeitslosenuntersttzung hat die ausweitung des arbeitsangebots im unteren lohnsegment ermglicht und bewerkstelligt dass die sozialversicherungspflichtige teil und vollzeitarbeit zunahm ein rckbau der reformen knnte diesen erfolg gefhrden key words  deutsches arbeitsmarktwunder hartzreformen lohnungleichheit teilzeitbeschftigung sep abstract systemic risk quantification in the current literature is concentrated on marketbased methods such as covaradrian and brunnermeier 2016 although it is easily implemented the interactions among the variables of interest and their joint distribution are less addressed to quantify systemic risk in a systemwide perspective we propose a networkbased factor copula approach to study systemic risk in a network of systemically important financial institutions sifis the factor copula model offers a variety of dependenciestail dependencies conditional on the chosen factor thus constructing conditional network given the network we identify the most connected sifi as the central sifi and demonstrate that its systemic risk exceeds that of noncentral sifis our identification of central sifis shows a coincidence with the bucket approach proposed by the basel committee on banking supervision but places more emphasis on modeling the interplay among sifis in order to generate systemwide quantifications the network defined by the tail dependence matrix is preferable to that defined by the pearson correlation matrix since it confirms that the identified central sifi through it severely impacts the system this study contributes to quantifying and ranking the systemic importance of sifis key words  factor copula network valueatrisk tail dependence eigenvector centrality sep abstract with increasing wind power penetration more and more volatile and weather dependent energy is fed into the german electricity system to manage the risk of windless days and transfer revenue risk from wind turbine owners to investors wind power derivatives were introduced these insurancelike securities ils allow to hedge the risk of unstable wind power production on exchanges like nasdaq and european energy exchange these products have been priced before using risk neutral pricing techniques we present a modern and powerful methodology to model weather derivatives with very skewed underlyings incorporating techniques from extreme event modelling to tune seasonal volatility and compare transformed gaussian and nongaussian carmap q models our results indicate that the transformed gaussian carmap q model is preferred over the nongaussian alternative with lvy increments outofsample backtesting results show good performance wrt burn analysis employing smooth market price of risk mpr estimates based on nasdaq weekly and monthly german wind power futures prices and german wind power utilisation as underlying a seasonal mpr of a smileshape is observed with positive values in times of high volatility eg winter months and negative values in times of low volatility and production eg in summer months we conclude that producers pay premiums to insure stable revenue steams while investors pay premiums when weather risk is high key words  market price of risk risk premium renewable energy wind power futures stochastic process expectile carma jump lvy transform logitnormal extreme sep abstract see content key words  time use work effort racial differences discrimination sep abstract cryptocurrencies have left the dark side of the finance universe and become an object of study for asset and portfolio management since they have a low liquidity compared to traditional assets one needs to take into account liquidity issues when one puts them into the same portfolio we propose use a liquidity bounded riskreturn optimization libro approach which is a combination of the markowitz framework under the liquidity constraints the results show that cryptocurrencies add value to a portfolio and the optimization approach is even able to increase the return of a portfolio and lower the volatility risk the codes used to obtain the results in this paper are available via wwwquantletde key words  cryptocurrency crix portfolio investment asset classes blockchain sep abstract the jel classification system is a standard way of assigning key topics to economic articles in order to make them more easily retrievable in the bulk of nowadays massive literature usually the jel journal of economic literature is picked by the authors bearing the risk of suboptimal assignment using the database of a collaborative research center from humboldtuniversitat zu berlin and xiamen university china we employ a new adaptive clustering technique to identify interpretable jel subclusters the proposed adaptive weights clustering awc is available on wwwquantletde and is based on the idea of locally weighting abstract in terms of cluster membership comparison with kmeans or cluto reveals excellent performance of awc key words  clustering  jel system  adaptive algorithm  economic articles  nonparametric sep abstract this paper contributes to model the industry interconnecting structure in a network context general predictive model rapach et al 2016 is extended to quantile lasso regression so as to incorporate tail risks in the construction of industry interdependency networks empirical results show a denser network with heterogeneous central industries in tail cases network dynamics demonstrate the variety of interdependency across time lower tail interdependency structure gives the most accurate outofsample forecast of portfolio returns and network centralitybased trading strategies seem to outperform market portfolios leading to the possible too central to fail argument key words  dynamic network interdependency general predictive model quantile lasso connectedness centrality prediction accuracy networkbased trading strategy sep  sep abstract this paper reviews the performance of the east german economy in the turbulent quartercentury following reunication and draws some conclusions for the reunication of north and south korea in this period the gap in output per capita between east and west germany declined at a speed not far from empirical estimates of the neoclas sical growth model yet systematic total factor productivity dieren tials persist despite identical institutional frameworks and signicant investment in the eastern regions at the same time regional dispar ities in income wellbeing and health are little dierent from those found within west germany and net migration has ceased on this human metric german unication has been an unqualied success for korea an eort of this dimension will be costly a backofthe envelope calculation suggests that korean unication will cost roughly twice as much as its german counterpart key words  east germany convergence total factor productiv ity korean unication sep abstract this paper proposes a test for missing at random mar the mar assumption is shown to be testable given instrumental variables which are independent of response given potential outcomes a nonparametric testing procedure based on integrated squared distance is proposed the statistics asymptotic distribution under the mar hypothesis is derived in particular our results can be applied to testing missing completely at random mcar a monte carlo study examines finite sample performance of our test statistic an empirical illustration analyzes the nonresponse mechanism in labor income questions key words  incomplete data missingdata mechanism selection model nonparametric hypothesis testing consistent testing instrumental variable series estimation sep abstract the interdependence dynamics and riskiness of financial institutions are the key features frequently tackled in financial econometrics we propose a tail event driven network quantile regression tenqr model which addresses these three aspects more precisely our framework captures the risk propagation and dynamics in terms of a quantile or expectile autoregression involving network effects quantified through an adjacency matrix to reflect the nature and risk content of systemic risk the construction of the adjacency matrix is suggested to include tail event covariates the model is evaluated using the sifis systemically important financial institutions identified by the financial stability board fsb as main players in the global financial system the risk decomposition analysis of it identifies the systemic importance of sifis and thus provides measures for the required level of additional loss absorbency it is discovered that the network effect as a function of the tail probability becomes more profound in stress situations and brings the various impacts to the sifis located in different geographic regions key words  systemic risk network analysis network autoregression tail event sep abstract in this paper we propose a new measure for systemic risk the financial risk meter frm this measure is based on the penalization parameter  of a linear quantile lasso regression the frm is calculated by taking the average of the penalization parameters over the 100 largest us publicly traded financial institutions we demonstrate the suitability of this risk measure by comparing the proposed frm to other measures for systemic risk such as vix srisk and google trends we find that mutual granger causality exists between the frm and these measures which indicates the validity of the frm as a systemic risk measure the implementation of this project is carried out using parallel computing the codes are published on wwwquantletde with keyword frm the r package riskanalytics is another tool with the purpose of integrating and facilitating the research calculation and analysis methods around the frm project the visualization and the uptodate frm can be found on httpfrmwiwihuberlinde key words  systemic risk quantile regression value at risk lasso parallel computing sep abstract systemically important banks are connected and have dynamic dependencies of their default probabilities an extraction of default factors from crosssectional credit default swaps cds curves allows to analyze the shape and the dynamics of the default probabilities extending the dynamic nelson siegel dns model we propose a network dns model to analyze the interconnectedness of default factors in a dynamic fashion and forecast the cds curves the extracted level factors representing longterm default risk demonstrate 855 total connectedness while the slope and the curvature factors document 7972 and 6294 total connectedness for the shortterm and middleterm default risk respectively the issues of default spillover and systemic risk should be weighted for the market participants with longer credit exposures and for regulators with a mission to stabilize financial markets the us banks contribute more to the longrun default spillover before 2012 whereas the european banks are major default transmitters during and after the european debt crisis either in the longrun or shortrun the outperformance of the network dns model indicates that the prediction on cds curve requires network information key words  cds network default risk variance decomposition risk management sep abstract more and more data are observed in form of curves numerous applications in finance neuroeconomics demographics and also weather and climate analysis make it necessary to extract common patterns and prompt joint modelling of individual curve variation focus of such joint variation analysis has been on fluctuations around a mean curve a statistical task that can be solved via functional pca in a variety of questions concerning the above applications one is more interested in the tail asking therefore for tail event curves tec studies with increasing dimension of curves and complexity of the covariates though one faces numerical problems and has to look into sparsity related issues here the idea of factorisable sparse tail event curves fastec via multivariate asymmetric least squares regression expectile regression in a highdimensional framework is proposed expectile regression captures the tail moments globally and the smooth loss function improves the convergence rate in the iterative estimation algorithm compared with quantile regression the necessary penalization is done via the nuclear norm finite sample oracle properties of the estimator associated with asymmetric squared error loss and nuclear norm regularizer are studied formally in this paper as an empirical illustration the fastec technique is applied on fmri data to see if individuals risk perception can be recovered by brain activities results show that factor loadings over different tail levels can be employed to predict individuals risk attitudes key words  highdimensionalmestimator nuclear norm regularizer factorization expectile regression fmri risk perception multivariate functional data sep abstract cryptocurrencies are more and more used in official cash  ows and exchange of goods bitcoin and the underlying blockchain technology have been looked at by big companies that are adopting and investing in this technology the crix index of cryptocurrencies huberlincrix indicates a wider acceptance of cryptos one reason for its prosperity certainly being a security aspect since the underlying network of cryptos is decentralized it is also unregulated and highly volatile making the risk assessment at any given moment difficult in message boards one nds a huge source of information in the form of unstructured text written by eg bitcoin developers and investors we collect from a popular crypto currency message board texts user information and associated time stamps we then provide an indicator for fraudulent schemes this indicator is constructed using dynamic topic modelling text mining and unsupervised machine learning we study how opinions and the evolution of topics are connected with big events in the cryptocurrency universe furthermore the predictive power of these techniques are investigated comparing the results to known events in the cryptocurrency space we also test hypothesis of selffulling prophecies and herding behaviour using the results key words  dynamic topic modelling cryptocurrencies financial risk sep abstract it is a challenging task to understand the complex dependency structures in an ultrahigh dimensional network especially when one concentrates on the tail dependency to tackle this problem we consider a network quantile autoregres sion model nqar to characterize the dynamic quantile behavior in a complex system in particular we relate responses to its connected nodes and node spe cic characteristics in a quantile autoregression process a minimum contrast estimation approach for the nqar model is introduced and the asymptotic properties are studied finally we demonstrate the usage of our model by in vestigating the nancial contagions in the chinese stock market accounting for shared ownership of companies key words  social network quantile regression autoregression sys temic risk financial contagion shared ownership sep abstract in the present paper we study the dynamics of penalization parameter  of the least absolute shrinkage and selection operator lasso method proposed by tibshirani 1996 and extended into quantile regression context by li and zhu 2008 the dynamic behaviour of the parameter  can be observed when the model is assumed to vary over time and therefore the fitting is performed with the use of moving windows the proposal of investigating time series of  and its dependency on model characteristics was brought into focus by hardle et al 2016 which was a foundation of financialriskmeter httpfrmwiwihuberlinde following the ideas behind the two aforementioned projects we use the derivation of the formula for the penalization parameter  as a result of the optimization problem this reveals three possible effects driving  variance of the error term correlation structure of the covariates and number of nonzero coefficients of the model our aim is to disentangle these three effect and investigate their relationship with the tuning parameter  which is conducted by a simulation study after dealing with the theoretical impact of the three model characteristics on  empirical application is performed and the idea of implementing the parameter  into a systemic risk measure is presented the codes used to obtain the results included in this work are available on httpquantletdeia key words   lasso quantile regression systemic risk high dimensions penalization parameter sep abstract cryptocurrencies have developed a vibrant market since bitcoin the rst cryptocurrency was created in 2009 we look at the properties of cryptocurrencies as nancial assets in a broad crosssection we discuss approaches of altcoins to generate value and their trading and information platforms then we investigate cryptocurrencies as alternative investment assets studying their returns and the comovements of altcoin prices with bitcoin and against each other we evaluate their addition to investors portfolios and document they are indeed able to enhance the diversication of portfolios due to their little comovements with established assets as well as with each other furthermore we evaluate pure portfolios of cryptocurrencies an equallyweighted one a valueweighted one and one based on the cryptocurrency index crix the crix portfolio displays lower risk than any individual of the liquid cryptocurrencies we also document the changing characteristics of the cryptocurrency market deepening liquidity is accompanied by a rise in market value and a growing number of altcoins is contributing larger amounts to aggregate cryptocurrency market capitalization key words   bitcoin cryptocurrency altcoins crix alternative investments portfolio selection sep abstract the increasing exposure to renewable energy has amplied the need for risk management in electricity markets electricity price risk poses a major challenge to market participants we propose an approach to model and fore cast electricity prices taking into account information on renewable energy production while most literature focuses on point forecasting our method ology forecasts the whole distribution of electricity prices and incorporates spike risk which is of great value for risk management it is based on func tional principal component analysis and timeadaptive nonparametric density estimation techniques the methodology is applied to electricity market data from germany we nd that renewable infeed eects both the location and the shape of spot price densities a comparison with benchmark methods and an application to risk management are provided key words  electricity prices residual load probabilistic forecasting value at risk expected shortfall functional data analysis sep abstract there are many environments in econometrics which require nonseparable modeling of a structural disturbance in a nonseparable model key conditions are validity of instrumental variables and monotonicity of the model in a scalar unobservable under these conditions the nonseparable model is equivalent to an instrumental quantile regression model a failure of the key conditions however makes instrumental quantile regression potentially inconsistent this paper develops a methodology for testing the hypothesis whether the instrumental quantile regression model is correctly specied our test statistic is asymptotically normally distributed under correct specication and consistent against any alternative model in addition test statistics to justify model simplication are established finite sample properties are examined in a monte carlo study and an empirical illustration key words  nonparametric quantile regression instrumental variable specication test local alternative nonlinear inverse problem sep abstract the crix cryptocurrency index has been constructed based on approximately 30 cryptos and captures high coverage of available market capitalisation the crix index family covers a range of cryptos based on dierent liquidity rules and various model selection criteria details of ecrix exact crix efcrix exact full crix and also intraday crix movements may be found on the webpage of huberlincrix key words  index construction crix information criteria model selection aic bic market analysis bitcoin cryptocurrency sep abstract limit order book contains comprehensive information of liquidity on bid and ask sides we propose a vector functional autoregressive vfar model to describe the dynamics of the limit order book and demand curves and utilize the tted model to predict the joint evolution of the liquidity demand and supply curves in the vfar framework we derive a closedform maximum likelihood estimator under sieves and provide the asymptotic consistency of the estimator in application to limit order book records of 12 stocks in nasdaq traded from 2 jan 2015 to 6 mar 2015 it shows the var model presents a strong predictability in liquidity curves with  values as high as 985 percent for insample estimation and 982 percent in outofsample forecast experiments it produces accurate 5 25 and 50minute forecasts with root mean squared error as low as 009 to 058 and mean absolute percentage error as low as 03 to 45 percent key words  limit order book liquidity risk multiple functional time series sep abstract mortality is different across countries states and regions several empirical research works however reveal that mortality trends exhibit a common pattern and show similar structures across populations the key element in analyzing mortality rate is a timevarying indicator curve our main interest lies in validating the existence of the common trends among these curves the similar gender differences and their variability in location among the curves at the national level motivated by the empirical findings we make the study of estimating and forecasting mortality rates based on a semiparametric approach which is applied to multiple curves with the shaperelated nonlinear variation this approach allows us to capture the common features contained in the curve functions and meanwhile provides the possibility to characterize the nonlinear variation via a few deviation parameters these parameters carry an instructive summary of the timevarying curve functions and can be further used to make a suggestive forecast analysis for countries with barren data sets in this research the model is illustrated with mortality rates of japan and china and extended to incorporate more countries all numerical procedures are transparent and reproduced on wwwquantletde key words  nonparametric smoothing parametric modeling common trend mortality leecarter method multipopulations sep abstract the s0 or da are important benchmarks for the financial industry these and other indices describe different compositions of certain segments of the financial markets for currency markets the imf offers the index sdr prior to the euro the ecu existed which was an index representing the development of european currencies it is surprising though to see that the common index providers have not mapped emerging ecoins into an index yet because with cryptos like bitcoin a new kind of asset of great public interest has arisen index providers decide on a fixed number of index constituents which will represent the market segment it is a huge challenge to set this fixed number and develop the rules to find the constituents especially since markets change and this has to be taken into account a method relying on the aic is proposed to quickly react to market changes and therefore enable us to create an index referred to as crix for the cryptocurrency market the codes used to obtain the results in this paper are available via wwwquantletde  key words  index construction model selection aic bitcoin cryptocurrency crix sep abstract publications are a vital element of any scientists career it is not only the number of media outlets but aslo the quality of published research that enters decisions on jobs salary tenure etc academic ranking scales in economics and other disciplines are therefore widely used in classification judgment and scientific depth of individual research these ranking systems are competing allow for different disciplinary gravity and sometimes give orthogonal results here a statistical analysis of the interconnection between handelsblatt hb research papers in economics repec here rp and google scholar gs systems is presented quantile regression allows us to successfully predict missing ranking data and to obtain a socalled hb common score and to carry out a crossrankings analysis based on the merged ranking data from different data providers we discuss the ranking systems dependence analyze the age effect and study the relationship between the research expertise areas and the ranking performance key words  scientometrics ranking quantile regression handelsblatt repec google scholar sep abstract oberwolfach report new developments in functional and highly multivariate statistical methodology key words  multivariate functional data highdimensional mestimators nuclear norm regularizer factor analysis expectile regression fmri risk perception sep abstract this paper reviews the dramatic and widely noted developments in the german labor market in the past decade and surveys the most plausible reasons for these changes alternative hypotheses are compared and contrasted i argue that the labor market reforms associated with the agenda 2010  the hartz reforms  played a role at least as great as that of increasing flexibility of wage determination and the allocation of hours across workers until 2010 the german economic miracle could be accounted for by an expansion of parttime work which has since been supplanted by a sustained expansion of fulltime employment supported by wage flexibility in this segment parttime employment represents an important new margin of flexibility in the german labor market key words  german labor market miracle hartz reforms parttime work wage inequality sep abstract in this paper we study the statistical properties of the moneyness scaling transformation by leung and sircar 2015 this transformation adjusts the moneyness coordinate of the implied volatility smile in an attempt to remove the discrepancy between the iv smiles for levered and unlevered etf options we construct bootstrap uniform confidence bands which indicate that in a statistical sense there remains a possibility that the implied volatility smiles are still not the same even after moneyness scaling has been performed this presents possible arbitrage opportunities on the letf market which can be exploited by traders we build possible arbitrage strategies by constructing portfolios with letf shares and options which possibly have a positive value at the point of creation and nonnegative value at the expiration time an empirical data application shows that there are indeed such opportunities in the market which result in riskfree gains for the investor a dynamic tradewiththesmile strategy based on a dynamic semiparametric factor model is presented this strategy utilizes the dynamic structure of implied volatility surface allowing outofsample forecasting and information on unleveraged etf options to construct theoretical onestepahead implied volatility surfaces the codes used to obtain the results in this paper are available on wwwquantletde key words  exchangetraded funds options moneyness scaling arbitrage bootstrap dynamic factor models sep abstract in this paper we suggest and analyze a new class of specification tests for random coefficient models these tests allow to assess the validity of central structural features of the model in particular linearity in coefficients and generalizations of this notion like a known nonlinear functional relationship they also allow to test for degeneracy of the distribution of a random coefficient ie whether a coefficient is fixed or random including whether an associated variable can be omitted altogether our tests are nonparametric in nature and use sieve estimators of the characteristic function we analyze their power against both global and local alternatives in large samples and through a monte carlo simulation study finally we apply our framework to analyze the specification in a heterogeneous random coefficients consumer demand model key words  nonparametric specication testing random coecients unobserved heterogeneity sieve method characteristic function consumer demand sep abstract we account for timevarying parameters in the conditional expectile based value at risk evar model evar appears more sensitive to the magnitude of portfolio losses compared to the quantilebased value at risk qvar nevertheless by fitting the models over relatively long adhoc fixed time intervals research ignores the potential timevarying parameter properties our work focuses on this issue by exploiting the local parametric approach in quantifying tail risk dynamics by achieving a balance between parameter variability and modelling bias one can safely fit a parametric expectile model over a stable interval of homogeneity empirical evidence at three stock markets from 2005 2014 shows that the parameter homogeneity interval lengths account for approximately 16 months of daily observations our method outperforms models with oneyear fixed intervals as well as quantile based candidates while employing a time invariant portfolio protection tipp strategy for the dax portfolio the tail risk measure implied by our model finally provides valuable insights for asset allocation and portfolio insurance key words  expectiles tail risk local parametric approach risk management sep abstract this paper addresses the problem of estimation of a nonparametric regression function from selectively observed data when selection is endogenous our approach relies on independence between covariates and selection conditionally on potential outcomes endogeneity of regressors is also allowed for in both cases consistent twostep estimation procedures are proposed and their rates of convergence are derived also pointwise asymptotic distribution of the estimators is established in addition we propose a nonparametric specification test to check the validity of our independence assumption finite sample properties are illustrated in a monte carlo simulation study and an empirical illustration key words  endogenous selection instrumental variable sieve minimum distance regression estimation convergence rate asymptotic normality hypothesis testing inverse problem sep abstract inflation expectation is acknowledged to be an important indicator for policy makers and financial investors to capture a more accurate realtime estimate of inflation expectation on the basis of financial markets we propose an arbitragefree model across different countries in a multimaturity term structure where we first estimate inflation expectation by modelling the nominal and inflationindexed bond yields jointly for each country the nelsonsiegel model is popular in fitting the term structure of government bond yields the arbitragefree model we proposed is the extension of the arbitragefree dynamic nelsonsiegel model proposed by christensen diebold and rudebusch 2011 we discover that the extracted common trend for inflation expectation is an important driver for each country of interest moreover the model will lead to an improved forecast in a benchmark level of inflation and will provide good implications for financial markets key words  inflation expectation dynamics arbitrage free yield curve modelling inflation risk sep abstract more and more companies start offering digital payment systems smartphones evolve to a digital wallet such that it seems like we are about to enter the era of digital finance in fact we are already inside an digital economy the market of ex x  finance money book you name it     has not only picked up enormous momentum but has become standard for driving innovative activities of the global economy a few clicks at y and payment at z brings our purchase to location w own currencies for the digital market were therefore just a matter of time the idea of the nobel laureate hayek see 1 to let companies offer concurrent currencies seemed for a long time scarcely probabilistic but the invention of the blockchain made it possible to fill his vision with life cryptocurrencies abbr cryptos came up and widened the angle towards this new level of economic interaction since bitcoins appearance a bunch of new cryptos spread the web and offered new ways of proliferation the crypto market then fanned out and showed clear signs of acceptance and deep liquidity so that one has to look closer at the general moves and dynamics key words  index construction crix risk analysis bitcoin cryptocurrency sep abstract a flexible framework for the analysis of tail events is proposed the framework contains tail moment measures that allow for expected shortfall es estimation connecting the implied tail thickness of a family of distributions with the quantile and expectile estimation a platform for risk assessment is provided es and implications for tail events under different distributional scenarios are investigated particularly we discuss the implications of increased tail risk for mixture distributions empirical results from the us german and uk stock markets as well as for the selected currencies indicate that es can be successfully estimated on a daily basis using a oneyear time horizon across different risk levels key words  expected shortfall expectiles tail risk risk management tail events tail moments sep abstract classical asset allocation methods have assumed that the distribution of asset returns is smooth well behaved with stable statistical moments over time the distribution is assumed to have constant moments with eg gaussian distribution that can be conveniently parameterised by the first two moments however with market volatility increasing over time and after recent crises asset allocators have cast doubts on the usefulness of such static methods that registered large drawdown of the portfolio others have suggested dynamic or synthetic strategies as alternatives which have proven to be costly to implement the authors propose and apply a method that focuses on the left tail of the distribution and does not require the knowledge of the entire distribution and may be less costly to implement the recently introduced tedas tail event driven asset allocation approach determines the dependence between assets at tail measures tedas uses adaptive lasso based quantile regression in order to determine an active set of portfolio elements with negative nonzero coefficients based on these active risk factors an adjustment for intertemporal dependency is made the authors extend tedas methodology to three gestalts differing in allocation weights determination a cornishfisher valueatrisk minimization  markowitz diversification rule and naive equal weighting tedas strategies significantly outperform other widely used allocation approaches on two asset markets german equity and global mutual funds key words  adaptive lasso portfolio optimisation quantile regression valueat risk tail events sep a standard quantitative method to access credit risk employs a factor model based on joint multi variate normal distribution properties by extending a onefactor gaussian copula model to make a more accurate default forecast this paper proposes to incorporate a statedependent recovery rate into the con ditional factor loading and model them by sharing a unique common factor the common factor governs the default rate and recovery rate simultaneously and creates their association implicitly in accordance with basel iii this paper shows that the tendency of default is more governed by systematic risk rather than idiosyncratic risk during a hectic period among the models considered the one with random fac tor loading and a statedependent recovery rate turns out to be the most superior on the default prediction key words factor model conditional factor loading statedependent recovery rate sep abstract we propose the use of a local autoregressive lar model for adaptive estimation and forecasting of three of chinas key macroeconomic variables gdp growth inflation and the 7day interbank lending rate the approach takes into account possible structural changes in the datagenerating process to select a local homogeneous interval for model estimation and is particularly wellsuited to a transition economy experiencing ongoing shifts in policy and structural adjustment our results indicate that the proposed method outperforms alternative models and forecast methods especially for forecast horizons of 3 to 12 months our 1quarter ahead adaptive forecasts even match the performance of the wellknown cmrc langrun survey forecast the selected homogeneous intervals indicate gradual changes in growth of industrial production driven by constant evolution of the real economy in china as well as abrupt changes in interestrate and inflation dynamics that capture monetary policy shifts keywords chinese economy local parametric models forecasting sep based on the leecarter lc model the benchmark in population forecasting a variety of extensions and modifications are proposed in this paper we investigate one of the extensions the hyndmanullah hu method and apply it to asian demographic data sets china japan and taiwan it combines ideas of functional principal component analysis fpca nonparametric smoothing and time series analysis based on this stochastic approach the demographic characteristics and trends in different asian regions are calculated and compared we illustrate that china and japan exhibited a similar demographic trend in the past decade we also compared the hu method with the lc model the hu method can explain more variation of the demographic dynamics when we have data of high quality however it also encounters problems and performs similarly as the lc model when we deal with limited and scarce data sets such as chinese data sets due to the substandard quality of the data and the population policy keywords functional principal component analysis nonparametric smoothing mortality forecasting fertility forecasting asian demography leecarter model hyndmanullah method sep we propose a semiparametric measure to estimate systemic interconnectedness across financial institutions based on taildriven spillover effects in a ultrahigh dimensional framework methodologically we employ a variable selection technique in a time series setting in the context of a singleindex model for a generalized quantile regression framework we can thus include more financial institutions into the analysis to measure their interdependencies in tails and at the same time to take into account nonlinear relationships between them a empirical application on a set of 200 publicly traded u s nancial institutions provides useful rankings of systemic exposure and systemic contribution at various stages of financial crisis network analysis its behaviour and dynamics allows us to characterize a role of each sector in the financial crisis and yields a new perspective of the nancial markets at the u s financial market 2007  2012 keywords systemic risk systemic risk network generalized quantile quantile single index regression value at risk covar lasso sep we analyse the shortterm spot price of european union allowances euas which is of particular importance in the transition of energy markets and for the development of new risk management strategies due to the characteristics of the price process such as volatility persistence breaks in the volatility process and heavytailed distributions we investigate the use of markov switching garch msgarch models on daily spot market data from the second trading period of the eu ets emphasis is given to shortterm forecasting of prices and volatility we find that msgarch models distinguish well between two states and that the volatility processes in the states are clearly different this finding can be explained by the eu ets design our results support the use of msgarch models for risk management especially because their forecasting ability is better than other markov switching or simple garch models keywords c emission allowances c emission trading spot price modelling markov switching garch models volatility forecasting sep a flexible statistical approach for the analysis of timevarying dynamics of transaction data on financial markets is here applied to intraday trading strategies a local adaptive technique is used to successfully predict financial time series ie the buyer and the sellerinitiated trading volumes and the order flow dynamics analysing order flow series and its information content of mini nikkei 225 index futures traded at the osaka securities exchange in 2012 and 2013 a datadriven optimal length of local windows up to approximately 12 hours is reasonable to capture parameter variations and is suitable for shortterm prediction our proposed trading strategies achieve statistical arbitrage opportunities and are therefore beneficial for quantitative finance practice multiplicative error models trading volume order flow forecasting sep portfolio selection and risk management are very actively studied topics in quantitative finance and applied statistics they are closely related to the dependency structure of portfolio assets or risk factors the correlation structure across assets and opposite tail movements are essential to the asset allocation problem since they determine the level of risk in a position correlation alone is not informative on the distributional details of the assets by introducing tedas tail event driven asset allocation one studies the dependence between assets at different quantiles in a hedging exercise tedas uses adaptive lasso based quantile regression in order to determine an active set of negative nonzero coefficients based on these active risk factors an adjustment for intertemporal correlation is made finally the asset allocation weights are determined via a cornishfisher valueatrisk optimization tedas is studied in simulation and a practical utilitybased example using hedge fund indices portfolio optimization asset allocation adaptive lasso quantile regression valueatrisk sep electricity load forecasts are an integral part of many decisionmaking pro cesses in the electricity market however most literature on electricity load forecasting concentrates on deterministic forecasts neglecting possibly impor tant information about uncertainty a more complete picture of future demand can be obtained by using distributional forecasts allowing for a more ecient decisionmaking a predictive density can be fully characterized by tail mea sures such as quantiles and expectiles furthermore interest often lies in the accurate estimation of tail events rather than in the mean or median we pro pose a new methodology to obtain probabilistic forecasts of electricity load that is based on functional data analysis of generalized quantile curves the core of the methodology is dimension reduction based on functional principal components of tail curves with dependence structure the approach has sev eral advantages such as exible inclusion of explanatory variables including meteorological forecasts and no distributional assumptions the methodol ogy is applied to load data from a transmission system operator tso and a balancing unit in germany our forecast method is evaluated against other models including the tso forecast model it outperforms them in terms of mean absolute percentage error mape and achieves a mape of 27 for the tso electricity load forecasting fpca sep 